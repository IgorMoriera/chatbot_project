# ðŸ§  Chatbot Documental  
![Python](https://img.shields.io/badge/python-3.11-blue) ![License](https://img.shields.io/badge/license-MIT-green)

<div align="center">
  <img src="https://github.com/IgorMoriera/chatbot_project/blob/master/logo.png" width="200" height="200" />
</div>


Um projeto em **Python 3.11** que implementa um chatbot capaz de responder perguntas com base em documentos locais (PDF, CSV e TXT). Este projeto utiliza tecnologias modernas para processar, indexar e gerar respostas a partir de documentos, oferecendo uma interface web (via Streamlit) e mobile (via Telegram) interativa.

### Tecnologias Utilizadas

- **LangChain**: para dividir textos em pedaÃ§os (chunking).
- **SentenceTransformers** (`all-MiniLM-L6-v2`): modelo para gerar embeddings de texto.
- **ChromaDB**: banco vetorial leve e persistente para armazenar embeddings.
- **Gemma3**: modelo de LLM local para geraÃ§Ã£o de respostas.
- **Streamlit**: interface web amigÃ¡vel e interativa.
- **Telegram**: interface mobile para interagir via chatbot.

---

## ðŸ” VisÃ£o Geral

O Chatbot Documental permite que usuÃ¡rios faÃ§am perguntas sobre o conteÃºdo de documentos locais e recebam respostas precisas baseadas em contexto recuperado. Ele funciona em quatro etapas principais:

1. **IngestÃ£o de Documentos**

   - LÃª arquivos em formatos PDF, CSV e TXT da pasta `data/`.
   - Divide o texto em pedaÃ§os menores (chunks) usando o LangChain.
   - Indexa os chunks no ChromaDB com metadados como fonte e nÃºmero da pÃ¡gina.

2. **RecuperaÃ§Ã£o de Contexto**

   - Busca os trechos mais relevantes para a pergunta do usuÃ¡rio no ChromaDB.
   - Extrai o texto e as fontes correspondentes para montar o contexto.

3. **GeraÃ§Ã£o de Resposta**

   - Cria um prompt com a pergunta e o contexto recuperado.
   - Usa o modelo Gemma3 (via Ollama) para gerar uma resposta detalhada.

4. **Interface Web e Mobile**

   - **Streamlit**: Interface web onde usuÃ¡rios podem interagir via chat em cima de documentos jÃ¡ indexados.
   - **Telegram**: Interface mobile que permite aos usuÃ¡rios fazer perguntas sobre documentos jÃ¡ indexados diretamente pelo Telegram.

---

## ðŸ“ Estrutura de Pastas

```
chatbot_project/
â”œâ”€â”€ .env                    # VariÃ¡veis de configuraÃ§Ã£o (API, paths, token do Telegram, etc.)
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â”œâ”€â”€ README.md
â”œâ”€â”€ data/                   # PDFs, CSVs e TXTs a indexar
â”‚   â”œâ”€â”€ exemplo.pdf
â”‚   â”œâ”€â”€ exemplo.csv
â”‚   â””â”€â”€ exemplo.txt
â”œâ”€â”€ loaders/                # Leitores de diferentes formatos
â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ csv_loader.py
â”‚   â””â”€â”€ txt_loader.py
â”œâ”€â”€ retriever/              # Chunking de texto
â”‚   â””â”€â”€ retriever.py
â”œâ”€â”€ embeddings/             # GeraÃ§Ã£o de embeddings
â”‚   â””â”€â”€ embedder.py
â”œâ”€â”€ store/                  # AbstraÃ§Ã£o do ChromaDB
â”‚   â””â”€â”€ chroma_store.py
â”œâ”€â”€ llm/                    # IntegraÃ§Ã£o com Gemma3
â”‚   â””â”€â”€ llm.py
â”œâ”€â”€ pipeline.py             # Script de ingestÃ£o dos dados
â”œâ”€â”€ app.py                  # Interface Streamlit
â””â”€â”€ telegram_bot.py         # IntegraÃ§Ã£o com Telegram
```

---

## âš™ï¸ InstalaÃ§Ã£o

### 1. PrÃ©-requisitos

- **Ambiente virtual** utilizando o Anaconda.


- **Python 3.11** (recomendado para compatibilidade).
- **Ollama** instalado e modelo **Gemma3** baixado localmente.
- **Git** para clonar o repositÃ³rio.
- **Telegram**: Crie um bot no Telegram e obtenha o token.

### 2. Clonar e Configurar o Ambiente

```bash
git clone https://github.com/seu-usuario/chatbot_documental_inteligente.git
cd chatbot_documental_inteligente
conda create --name nome_do_ambiente python=3.11
conda activate nome_do_ambiente
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configurar VariÃ¡veis de Ambiente

1. **Crie** um arquivo chamado `.env` na raiz do seu projeto.  
2. **Copie** e **cole** o conteÃºdo abaixo dentro dele.  
3. **Substitua** cada valor placeholder pelo dado real do seu ambiente.  
4. **Salve** o arquivo.

```VariÃ¡veis de ambiente
# DiretÃ³rio dos arquivos de entrada/saÃ­da
DATA_DIR=/caminho/para/seus/arquivos

# Token do Telegram Bot (obtido via @BotFather)
TELEGRAM_TOKEN=SEU_TOKEN_DO_TELEGRAM_AQUI

# Quantos â€œchunksâ€ recuperar por requisiÃ§Ã£o (opcional; padrÃ£o: 3)
K_RESULTS=3

# Endpoint e modelo para geraÃ§Ã£o via Ollama/Gemma3
OLLAMA_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=gemma3:1b

# Nome do modelo de embeddings e chave da Hugging Face
MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
HF_API_KEY=SUA_HUGGINGFACE_API_KEY_AQUI

# Pasta onde o Chroma vai persistir o banco vetorial
CHROMA_PERSIST_DIR=chroma_db
```

**Nota**: Substitua `*` pelo token do seu bot do Telegram.


## ðŸš€ Como Usar

### 1. IngestÃ£o de Documentos

Execute o script de ingestÃ£o para indexar os documentos da pasta `data/`:

```bash
python pipeline.py
```

**SaÃ­da esperada:**

```
ðŸ—‘ï¸  Limpando coleÃ§Ã£o Chroma anterior...
âœ… ColeÃ§Ã£o limpa.

ðŸ“‚  Carregado 5 documentos de 'exemplo.pdf'
âœ…  'exemplo.pdf': 20 chunks indexados
â€¦
ðŸ  IngestÃ£o concluÃ­da: 50 novos chunks de data
ðŸ“Š Total de chunks na coleÃ§Ã£o: 50
```

> **Nota:** Execute este passo antes de iniciar as interfaces web ou Telegram.

### 2. Iniciar a Interface Streamlit

```bash
streamlit run app.py
```

Acesse `http://localhost:8501` no navegador e:

- Digite perguntas no chat referente aos documentos indexados.
- Veja respostas, contexto, fontes e tempo de processamento.

### 3. Interagir via Telegram

ApÃ³s configurar o token do Telegram no `.env`, execute o script do bot:

```bash
python telegram_bot.py
```

- No Telegram, inicie uma conversa com o seu bot.
- Envie perguntas sobre os documentos jÃ¡ indexados.
- Receba respostas diretamente no chat do Telegram.

### Exemplo de Uso

**Pergunta (Telegram ou Streamlit):** "O que diz o exemplo.pdf sobre sustentabilidade?"\
**Resposta:** "O exemplo.pdf menciona que a sustentabilidade envolve equilibrar recursos naturais e desenvolvimento econÃ´mico..."\
**Contexto:** Trecho do PDF com a fonte indicada.

---

## ðŸ§© Principais MÃ³dulos

| MÃ³dulo | FunÃ§Ã£o Principal |
| --- | --- |
| `loaders/*.py` | LÃª PDF, CSV e TXT, retornando texto e metadados. |
| `retriever/retriever.py` | Divide textos em chunks com `RecursiveCharacterTextSplitter`. |
| `embeddings/embedder.py` | Gera embeddings usando `SentenceTransformer`. |
| `store/chroma_store.py` | Gerencia o ChromaDB (indexaÃ§Ã£o e limpeza). |
| `llm/llm.py` | Integra com Ollama/Gemma3 para gerar respostas. |
| `pipeline.py` | Executa a ingestÃ£o completa dos documentos. |
| `app.py` | Interface Streamlit com chat e visualizaÃ§Ã£o de resultados. |
| `telegram_bot.py` | IntegraÃ§Ã£o com Telegram para interaÃ§Ãµes via chat. |

---

## âš ï¸ Dicas de Ajuste e ResoluÃ§Ã£o de Problemas

- **Python 3.11+**: Essencial para evitar erros de sintaxe como `dict | None`.
- **Erro na coleÃ§Ã£o Chroma**: Delete a pasta `chroma_db/` e reexecute `pipeline.py`.
- **Ajuste de chunks**: Modifique `chunk_size` e `chunk_overlap` em `retriever/retriever.py`.
- **Mais/menos contexto**: Altere `K_RESULTS` no `.env` ou `app.py`.
- **Timeout do LLM**: Ajuste o parÃ¢metro `timeout` em `llm/llm.py`.
- **Telegram**: Certifique-se de que o token estÃ¡ corretamente configurado no `.env`.

---

## ðŸ¤ Contribuindo

Quer ajudar a melhorar o projeto? Siga esses passos:

1. FaÃ§a um **fork** do repositÃ³rio.
2. Crie uma branch: `git checkout -b feature/sua-ideia`.
3. FaÃ§a commits claros e envie um **Pull Request** com uma descriÃ§Ã£o detalhada.

> **Dica**: ContribuiÃ§Ãµes para melhorar a interface web (Streamlit) ou mobile (Telegram) sÃ£o especialmente bem-vindas!

---

## ðŸ“„ LicenÃ§a

MIT Â© Igor Moreira\
Use, modifique e distribua este projeto livremente!

---

> Desenvolvido por Igor Moreira â€“ Data Scientist & Engenheiro de Dados\
> Contato: igor.moreira@fat.uerj.br