"""
app.py

AplicaÃ§Ã£o Streamlit para o Chatbot Documental Inteligente.
Permite ao usuÃ¡rio:
  - Fazer perguntas sobre o conteÃºdo indexado de documentos.
  - Visualizar trechos de contexto recuperados.
  - Conferir tempo de resposta e fontes utilizadas.
"""

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
import os
import time
from typing import Tuple, List

import streamlit as st
from dotenv import load_dotenv

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Carregamento de variÃ¡veis de ambiente
load_dotenv()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ConfiguraÃ§Ãµes globais
# NÃºmero padrÃ£o de resultados contextuais a recuperar
K_RESULTS = int(os.getenv("K_RESULTS", 3))

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ImportaÃ§Ã£o de mÃ³dulos internos
# Busca o cliente ChromaDB e a funÃ§Ã£o de geraÃ§Ã£o via Ollama/Gemma3
try:
    from store.chroma_store import collection
    from llm.llm import obter_resposta_llama
except ImportError as e:
    st.error(f"Erro crÃ­tico: mÃ³dulos nÃ£o encontrados â€“ {e}")
    st.stop()


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# FunÃ§Ã£o auxiliar para recuperaÃ§Ã£o de contexto
def get_context(query: str, k: int = K_RESULTS) -> Tuple[str, List[str]]:
    """
    Busca os k trechos mais relevantes no ChromaDB e extrai as fontes.

    Args:
        query (str): Pergunta inserida pelo usuÃ¡rio.
        k (int): Quantidade de chunks a retornar para formar o contexto.

    Returns:
        Tuple[str, List[str]]:
            - String com os trechos concatenados.
            - Lista de nomes de arquivos que serviram de fonte.
    """
    try:
        # Executa a query no ChromaDB incluindo documentos e metadados
        result = collection.query(
            query_texts=[query],
            n_results=k,
            include=["documents", "metadatas"]
        )
        documentos = result["documents"][0]
        metadados  = result["metadatas"][0]

        # Extrai nomes de fonte Ãºnicos para apresentar ao usuÃ¡rio
        fontes = list({m["source"] for m in metadados if "source" in m})
        contexto = "\n\n".join(documentos)
        return contexto, fontes

    except Exception as e:
        st.error(f"Erro na busca de contexto: {e}")
        return "", []

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ConfiguraÃ§Ã£o da pÃ¡gina Streamlit
st.set_page_config(
    page_title="ğŸ§  Chatbot Documental Inteligente",
    page_icon="ğŸ¤–",
    layout="wide"
)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# CSS customizado para balÃµes de conversa
st.markdown("""
<style>
    .user-message {
        padding: 1rem;
        border-radius: 15px;
        background: #3C3D37;
        margin: 1rem 0;
        max-width: 80%;
        float: right;
        color: #FFFFFF;
        border: 1px solid #bdc3c7;
        font-weight: bold;
    }
    .bot-message {
        padding: 1rem;
        border-radius: 15px;
        background: #697565;
        margin: 1rem 0;
        max-width: 80%;
        float: left;
        color: #FFFFFF;
        border: 1px solid #aed6f1;
        line-height: 1.6;
    }
    .css-1q1n0ol {
        color: #34495e !important;
    }
</style>
""", unsafe_allow_html=True)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Estado de sessÃ£o para histÃ³rico de conversas
if "history" not in st.session_state:
    st.session_state.history = []  # Cada item: dict com pergunta, resposta, tempo, fontes, contexto

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# TÃ­tulo e subtÃ­tulo da aplicaÃ§Ã£o
st.title("ğŸ§  Chatbot Documental Inteligente")
st.caption("FaÃ§a perguntas sobre seus documentos e obtenha respostas contextualizadas")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Ãrea de entrada de perguntas
with st.container():
    user_question = st.chat_input("Digite sua pergunta...", key="input")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# Processamento da pergunta ao clicar em "Enviar"
if user_question:
    with st.spinner("ğŸ” Analisando documentos e gerando resposta..."):
        start_time = time.time()
        try:
            # 1) Recupera contexto e fontes
            contexto, fontes = get_context(user_question)

            # 2) Gera resposta via LLM local (Gemma3)
            resposta = obter_resposta_llama(
                pergunta=user_question,
                contexto=contexto
            )

            # 3) Calcula tempo de processamento
            processing_time = time.time() - start_time

            # 4) Armazena interaÃ§Ã£o no histÃ³rico
            st.session_state.history.append({
                "pergunta": user_question,
                "resposta": resposta,
                "tempo": f"{processing_time:.2f}s",
                "fontes": fontes,
                "contexto": contexto
            })

        except Exception as e:
            # Em caso de erro, notifica e registra apenas a pergunta
            st.error(f"Erro ao processar pergunta: {e}")
            st.session_state.history.append({
                "pergunta": user_question,
                "resposta": "Desculpe, ocorreu um erro ao processar sua solicitaÃ§Ã£o.",
                "erro": True
            })

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# RenderizaÃ§Ã£o do histÃ³rico de conversas
for entry in st.session_state.history:
    # Mensagem do usuÃ¡rio (direita)
    st.markdown(
        f"<div class='user-message'>ğŸ™‹ **VOCÃŠ:** {entry['pergunta']}</div>",
        unsafe_allow_html=True
    )

    # Mensagem do assistente (esquerda)
    if entry.get("erro"):
        st.markdown(
            f"<div class='bot-message'>âŒ **ERRO:** {entry['resposta']}</div>",
            unsafe_allow_html=True
        )
    else:
        st.markdown(
            f"<div class='bot-message'>ğŸ¤– **ASSISTENTE:** {entry['resposta']}</div>",
            unsafe_allow_html=True
        )

        # Exibe tempo e fontes
        cols = st.columns([1, 4])
        with cols[0]:
            st.caption(f"â±ï¸ {entry['tempo']}")
        with cols[1]:
            if entry['fontes']:
                st.caption(f"ğŸ“š Fontes: {', '.join(entry['fontes'])}")

        # Expande para mostrar contexto completo
        with st.expander("ğŸ” Ver contexto utilizado"):
            st.write(entry['contexto'])

    st.divider()
